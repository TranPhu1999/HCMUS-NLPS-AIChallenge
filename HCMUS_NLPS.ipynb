{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranPhu1999/HCMUS-NLPS-AIChallenge/blob/main/HCMUS_NLPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7p7iuQEwbcY"
      },
      "source": [
        "# Tham khảo\n",
        "- Paper: https://paperswithcode.com/paper/frozen-in-time-a-joint-video-and-image\n",
        "- Towee repo: https://github.com/towhee-io/towhee\n",
        "- Video-text retrival: https://codelabs.towhee.io/how-to-build-a-text-video-retrieval-engine/index#1\n",
        "- Similar video: https://codelabs.towhee.io/build-a-reverse-video-search-engine-in-minutes/index#0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "Download KeyFrames extracted from videos"
      ],
      "metadata": {
        "id": "XHVOWsH5oeJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ANjUARZ85tTx",
        "outputId": "5e4a61a9-dc1a-40ce-95c5-6088b4010dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V00.zip\n",
        "# !unzip KeyFramesC00_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC00_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V00.zip\n",
        "# !unzip KeyFramesC01_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC01_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V00.zip\n",
        "# !unzip KeyFramesC02_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC02_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V01.zip\n",
        "# !unzip KeyFramesC00_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC00_V01.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V01.zip\n",
        "# !unzip KeyFramesC01_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC01_V01.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V01.zip\n",
        "# !unzip KeyFramesC02_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC02_V01.zip"
      ],
      "metadata": {
        "id": "fvg110Sl5Nu8",
        "outputId": "60cabcc4-61f7-45e6-c246-8072c1a65720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-30 08:02:21--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V00.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.52, 125.212.206.48\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9207919383 (8.6G) [application/zip]\n",
            "Saving to: ‘KeyFramesC01_V00.zip’\n",
            "\n",
            "KeyFramesC01_V00.zi 100%[===================>]   8.58G  12.8MB/s    in 15m 43s \n",
            "\n",
            "2022-10-30 08:18:06 (9.31 MB/s) - ‘KeyFramesC01_V00.zip’ saved [9207919383/9207919383]\n",
            "\n",
            "--2022-10-30 08:18:06--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V00.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11260966214 (10G) [application/zip]\n",
            "Saving to: ‘KeyFramesC02_V00.zip’\n",
            "\n",
            "KeyFramesC02_V00.zi 100%[===================>]  10.49G  12.8MB/s    in 14m 7s  \n",
            "\n",
            "2022-10-30 08:32:14 (12.7 MB/s) - ‘KeyFramesC02_V00.zip’ saved [11260966214/11260966214]\n",
            "\n",
            "--2022-10-30 08:32:14--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4561839380 (4.2G) [application/zip]\n",
            "Saving to: ‘KeyFramesC00_V01.zip’\n",
            "\n",
            "KeyFramesC00_V01.zi 100%[===================>]   4.25G  12.7MB/s    in 5m 50s  \n",
            "\n",
            "2022-10-30 08:38:06 (12.4 MB/s) - ‘KeyFramesC00_V01.zip’ saved [4561839380/4561839380]\n",
            "\n",
            "--2022-10-30 08:38:06--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.52, 125.212.206.48\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4285711517 (4.0G) [application/zip]\n",
            "Saving to: ‘KeyFramesC01_V01.zip’\n",
            "\n",
            "KeyFramesC01_V01.zi 100%[===================>]   3.99G  12.4MB/s    in 5m 26s  \n",
            "\n",
            "2022-10-30 08:43:33 (12.5 MB/s) - ‘KeyFramesC01_V01.zip’ saved [4285711517/4285711517]\n",
            "\n",
            "--2022-10-30 08:43:34--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8975732543 (8.4G) [application/zip]\n",
            "Saving to: ‘KeyFramesC02_V01.zip’\n",
            "\n",
            "KeyFramesC02_V01.zi 100%[===================>]   8.36G  12.9MB/s    in 11m 16s \n",
            "\n",
            "2022-10-30 08:54:51 (12.7 MB/s) - ‘KeyFramesC02_V01.zip’ saved [8975732543/8975732543]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "print(\"Total number of images: {}\".format(len(glob.glob(\"./KeyFrames/*/*.jpg\"))))"
      ],
      "metadata": {
        "id": "qPMCpuK3O9Qw",
        "outputId": "e9ed03b9-b274-4111-ebe7-affad7c9f696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "226636"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n",
        "%ll"
      ],
      "metadata": {
        "id": "via9A6NTKald",
        "outputId": "03fce086-ba4f-4eaa-9594-69ee00ea153e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n",
            "total 14999\n",
            "-rw------- 1 root 15353881 Oct 30 09:10 key_frame_df.csv\n",
            "-rw------- 1 root      112 Oct 30 09:07 requirements.txt\n",
            "drwx------ 2 root     4096 Oct 30 09:18 \u001b[0m\u001b[01;34mvi_en_translate\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAiErZ4uzTj"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo7fV_2K3Ubs"
      },
      "outputs": [],
      "source": [
        "import towhee\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MyLrGOr3Ubv"
      },
      "source": [
        "# Vietnamese Engslish Translate\n",
        "Download pretrained model Vietnamese-English from VinAI repo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"vi_en_translate\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "IWk8h8YZLHq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd vi_en_translate\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/pytorch_model.bin\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/config.json\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/sentencepiece.bpe.model\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/tf_model.h5\n",
        "%cd .."
      ],
      "metadata": {
        "id": "_1wbk9nCKkqo",
        "outputId": "55644f24-a55b-45a0-9eb7-9591d2a03e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS/vi_en_translate\n",
            "--2022-10-30 09:16:31--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 52.3.185.208, 34.227.129.17, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.3.185.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/245f08542f8b87d4d8721912ba3ae7d02feb5b72943d759135f4d551d4f32455?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1667380592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvMjQ1ZjA4NTQyZjhiODdkNGQ4NzIxOTEyYmEzYWU3ZDAyZmViNWI3Mjk0M2Q3NTkxMzVmNGQ1NTFkNGYzMjQ1NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnB5dG9yY2hfbW9kZWwuYmluJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNTkyfX19XX0_&Signature=yVjattFQ3GcSzicAl-H3aldoA78s9hsIMSxl2Be1uAyqvFe8rQlXkfwJHq-3PmVuj-2FR39Dfmfeww06SAFR4ChJaMCDfss6RbvURS5a-ZvkLhaf87~zPJrzUkOQExwwvxAomtjuPRuaHEvvbCMNdrXStxBqz2gc132HQK4-ul5fipQGBsBCykUGq88FtFDTEY2zlGitWpxONkBIQevzGTSs-frxCVKv-IfKTJQRsZtwbXqaquKtLlsF0~WHrpu6gKxURG7cyy-dDkcvMe1Xb8dF72rj49A52yafYq-x2yl1XWmoPe8m232UBEREz43sNYNEb83v1ImrF0FL13tOVg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:16:32--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/245f08542f8b87d4d8721912ba3ae7d02feb5b72943d759135f4d551d4f32455?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1667380592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvMjQ1ZjA4NTQyZjhiODdkNGQ4NzIxOTEyYmEzYWU3ZDAyZmViNWI3Mjk0M2Q3NTkxMzVmNGQ1NTFkNGYzMjQ1NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnB5dG9yY2hfbW9kZWwuYmluJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNTkyfX19XX0_&Signature=yVjattFQ3GcSzicAl-H3aldoA78s9hsIMSxl2Be1uAyqvFe8rQlXkfwJHq-3PmVuj-2FR39Dfmfeww06SAFR4ChJaMCDfss6RbvURS5a-ZvkLhaf87~zPJrzUkOQExwwvxAomtjuPRuaHEvvbCMNdrXStxBqz2gc132HQK4-ul5fipQGBsBCykUGq88FtFDTEY2zlGitWpxONkBIQevzGTSs-frxCVKv-IfKTJQRsZtwbXqaquKtLlsF0~WHrpu6gKxURG7cyy-dDkcvMe1Xb8dF72rj49A52yafYq-x2yl1XWmoPe8m232UBEREz43sNYNEb83v1ImrF0FL13tOVg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.109, 18.64.174.43, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1794247767 (1.7G) [application/zip]\n",
            "Saving to: ‘pytorch_model.bin’\n",
            "\n",
            "pytorch_model.bin   100%[===================>]   1.67G  46.9MB/s    in 38s     \n",
            "\n",
            "2022-10-30 09:17:10 (45.1 MB/s) - ‘pytorch_model.bin’ saved [1794247767/1794247767]\n",
            "\n",
            "--2022-10-30 09:17:10--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1466 (1.4K) [text/plain]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-30 09:17:10 (101 MB/s) - ‘config.json’ saved [1466/1466]\n",
            "\n",
            "--2022-10-30 09:17:10--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/sentencepiece.bpe.model\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/acd6ee71173d8414b78c0a961d8913c37e6ff78988a7282d69a9242156042063?response-content-disposition=attachment%3B%20filename%3D%22sentencepiece.bpe.model%22&Expires=1667380631&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvYWNkNmVlNzExNzNkODQxNGI3OGMwYTk2MWQ4OTEzYzM3ZTZmZjc4OTg4YTcyODJkNjlhOTI0MjE1NjA0MjA2Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNlbnRlbmNlcGllY2UuYnBlLm1vZGVsJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMxfX19XX0_&Signature=nL3NnM59yX6-4pHtriSRZETJf4oPyIBpTbXi-uSF3~f54srp7yinw~HBysuJEs99jGrdbWF-hcTRY4i10njfPIX4jcSbxpECnzfvJAJ~zyy68EbQ8GtpoPLW0lEGfZ5ScUfzNthvAEFN~VWQDofIIs2tVDjFbTZNH~2uzh1Cpr03veZdUoijEBw4ka82kvAhYVCYg0QKyr8sYxMPPJTwZ38JsnGaL4hYFI6nWZF8MhsKUdqA0OjT1B9EsmTj7~4u8U7WscitWO7DVxXWpyBl2LkYY5~uBDqzNu9T-TOyxQtpmDV9b0VR3mbaSJKLQV20S8kA38jH5WzzQDoiiV99Ww__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:17:11--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/acd6ee71173d8414b78c0a961d8913c37e6ff78988a7282d69a9242156042063?response-content-disposition=attachment%3B%20filename%3D%22sentencepiece.bpe.model%22&Expires=1667380631&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvYWNkNmVlNzExNzNkODQxNGI3OGMwYTk2MWQ4OTEzYzM3ZTZmZjc4OTg4YTcyODJkNjlhOTI0MjE1NjA0MjA2Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNlbnRlbmNlcGllY2UuYnBlLm1vZGVsJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMxfX19XX0_&Signature=nL3NnM59yX6-4pHtriSRZETJf4oPyIBpTbXi-uSF3~f54srp7yinw~HBysuJEs99jGrdbWF-hcTRY4i10njfPIX4jcSbxpECnzfvJAJ~zyy68EbQ8GtpoPLW0lEGfZ5ScUfzNthvAEFN~VWQDofIIs2tVDjFbTZNH~2uzh1Cpr03veZdUoijEBw4ka82kvAhYVCYg0QKyr8sYxMPPJTwZ38JsnGaL4hYFI6nWZF8MhsKUdqA0OjT1B9EsmTj7~4u8U7WscitWO7DVxXWpyBl2LkYY5~uBDqzNu9T-TOyxQtpmDV9b0VR3mbaSJKLQV20S8kA38jH5WzzQDoiiV99Ww__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1879553 (1.8M) [binary/octet-stream]\n",
            "Saving to: ‘sentencepiece.bpe.model’\n",
            "\n",
            "sentencepiece.bpe.m 100%[===================>]   1.79M  11.1MB/s    in 0.2s    \n",
            "\n",
            "2022-10-30 09:17:11 (11.1 MB/s) - ‘sentencepiece.bpe.model’ saved [1879553/1879553]\n",
            "\n",
            "--2022-10-30 09:17:11--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/tf_model.h5\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/9188bf7fa76a84bb37c6dabcb73ad57c3b4a799aa4c3ea8bcb38b49029444957?response-content-disposition=attachment%3B%20filename%3D%22tf_model.h5%22&Expires=1667380632&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvOTE4OGJmN2ZhNzZhODRiYjM3YzZkYWJjYjczYWQ1N2MzYjRhNzk5YWE0YzNlYThiY2IzOGI0OTAyOTQ0NDk1Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmX21vZGVsLmg1JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMyfX19XX0_&Signature=JZEZLWghy5C03mS7IboX7jRip0Gq8w9eG9nccmhZ33smFCJp~xLLnvLYqCxJEOFybk4MXagbCu7K9RY9xX5G3in-v7kUNP8ayDiGSzLx1bfb3cGmbn-cwerMCjckV3KuAscQOCZCMQCRYAXfMz5hvXZMW1Ihf9An9lQxsVNEs9rAVwdT2TYCe0ZV1gtniIVjguz7M3vRItEWSBcAw~JoR9htgNpQ80fSH7DO79Sz3xMcqBNL-q-YTEkkb-3Z49~dAxNhTTEui~hAjN87E3z3AaNJTwJY18J6RHkoSs9fnJnbSA5qpOhZUgXE-rq36JYfFYwEXrsWcOPbntSBnfsAUw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:17:11--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/9188bf7fa76a84bb37c6dabcb73ad57c3b4a799aa4c3ea8bcb38b49029444957?response-content-disposition=attachment%3B%20filename%3D%22tf_model.h5%22&Expires=1667380632&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvOTE4OGJmN2ZhNzZhODRiYjM3YzZkYWJjYjczYWQ1N2MzYjRhNzk5YWE0YzNlYThiY2IzOGI0OTAyOTQ0NDk1Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmX21vZGVsLmg1JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMyfX19XX0_&Signature=JZEZLWghy5C03mS7IboX7jRip0Gq8w9eG9nccmhZ33smFCJp~xLLnvLYqCxJEOFybk4MXagbCu7K9RY9xX5G3in-v7kUNP8ayDiGSzLx1bfb3cGmbn-cwerMCjckV3KuAscQOCZCMQCRYAXfMz5hvXZMW1Ihf9An9lQxsVNEs9rAVwdT2TYCe0ZV1gtniIVjguz7M3vRItEWSBcAw~JoR9htgNpQ80fSH7DO79Sz3xMcqBNL-q-YTEkkb-3Z49~dAxNhTTEui~hAjN87E3z3AaNJTwJY18J6RHkoSs9fnJnbSA5qpOhZUgXE-rq36JYfFYwEXrsWcOPbntSBnfsAUw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1794265048 (1.7G) [application/octet-stream]\n",
            "Saving to: ‘tf_model.h5’\n",
            "\n",
            "tf_model.h5         100%[===================>]   1.67G  51.3MB/s    in 50s     \n",
            "\n",
            "2022-10-30 09:18:01 (34.4 MB/s) - ‘tf_model.h5’ saved [1794265048/1794265048]\n",
            "\n",
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFk642OM3Ubx"
      },
      "outputs": [],
      "source": [
        "dict_map = {\n",
        "    \"òa\": \"oà\",\"Òa\": \"Oà\",\"ÒA\": \"OÀ\",\"óa\": \"oá\",\"Óa\": \"Oá\",\"ÓA\": \"OÁ\",\"ỏa\": \"oả\",\"Ỏa\": \"Oả\",\"ỎA\": \"OẢ\",\"õa\": \"oã\",\n",
        "    \"Õa\": \"Oã\",\"ÕA\": \"OÃ\",\"ọa\": \"oạ\",\"Ọa\": \"Oạ\",\"ỌA\": \"OẠ\",\"òe\": \"oè\",\"Òe\": \"Oè\",\"ÒE\": \"OÈ\",\"óe\": \"oé\",\"Óe\": \"Oé\",\n",
        "    \"ÓE\": \"OÉ\",\"ỏe\": \"oẻ\",\"Ỏe\": \"Oẻ\",\"ỎE\": \"OẺ\",\"õe\": \"oẽ\",\"Õe\": \"Oẽ\",\"ÕE\": \"OẼ\",\"ọe\": \"oẹ\",\"Ọe\": \"Oẹ\",\"ỌE\": \"OẸ\",\n",
        "    \"ùy\": \"uỳ\",\"Ùy\": \"Uỳ\",\"ÙY\": \"UỲ\",\"úy\": \"uý\",\"Úy\": \"Uý\",\"ÚY\": \"UÝ\",\"ủy\": \"uỷ\",\"Ủy\": \"Uỷ\",\"ỦY\": \"UỶ\",\"ũy\": \"uỹ\",\n",
        "    \"Ũy\": \"Uỹ\",\"ŨY\": \"UỸ\",\"ụy\": \"uỵ\",\"Ụy\": \"Uỵ\",\"ỤY\": \"UỴ\",\n",
        "    }\n",
        "\n",
        "def strip_accents(s):\n",
        "       return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                  if unicodedata.category(c) != 'Mn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mS-5Nwm3Ubz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"./vi_en_translate/\", src_lang=\"vi_VN\")\n",
        "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"./vi_en_translate/\")\n",
        "\n",
        "def translate_vi2en(vi_text: str) -> str:\n",
        "    for i, j in dict_map.items():\n",
        "        vi_text = vi_text.replace(i, j)\n",
        "    input_ids = tokenizer_vi2en(vi_text, return_tensors=\"pt\").input_ids\n",
        "    output_ids = model_vi2en.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        top_k=100,\n",
        "        top_p=0.8,\n",
        "        decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "    en_text = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    en_text = \" \".join(en_text)\n",
        "    en_text = strip_accents(en_text)\n",
        "    en_text = en_text.replace(\"\\\\\",\"\")\n",
        "    return en_text\n",
        "\n",
        "# vi_text = \"Cô cho biết: trước giờ tôi không đến phòng tập công cộng, mà tập cùng giáo viên Yoga riêng hoặc tự tập ở nhà. Khi tập thể dục trong không gian riêng tư, tôi thoải mái dễ chịu hơn.\"\n",
        "# print(translate_vi2en(vi_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFrsqOE1wvoP"
      },
      "source": [
        "# Towhee text-video inference\n",
        "This section is only using example data, you can modfiy it to use your custom data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhuwMvBMvWhO"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/towhee-io/examples/releases/download/data/text_video_search.zip -O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep6Mn3t0zR2s"
      },
      "outputs": [],
      "source": [
        "# Nếu chạy không được lệnh này thì ra ngoài folder rồi tự unzip\n",
        "!unzip -q -o text_video_search.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtBQERZFzWcX"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-BaMxTszcxW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "raw_video_path = './test_1k_compress' # 1k test video path.\n",
        "test_csv_path = './MSRVTT_JSFUSION_test.csv' # 1k video caption csv.\n",
        "\n",
        "test_sample_csv_path = './MSRVTT_JSFUSION_test_sample.csv'\n",
        "\n",
        "sample_num = 1000 # you can change this sample_num to be smaller, so that this notebook will be faster.\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "print('length of all test set is {}'.format(len(test_df)))\n",
        "sample_df = test_df.sample(sample_num, random_state=42)\n",
        "\n",
        "sample_df['video_path'] = sample_df.apply(lambda x:os.path.join(raw_video_path, x['video_id']) + '.mp4', axis=1)\n",
        "\n",
        "sample_df.to_csv(test_sample_csv_path)\n",
        "print('random sample {} examples'.format(sample_num))\n",
        "\n",
        "df = pd.read_csv(test_sample_csv_path)\n",
        "\n",
        "df[['video_id', 'video_path', 'sentence']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjbavLhRzkoT"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "from pathlib import Path\n",
        "import towhee\n",
        "from PIL import Image\n",
        "\n",
        "def display_gif(video_path_list, text_list):\n",
        "    html = ''\n",
        "    for video_path, text in zip(video_path_list, text_list):\n",
        "        html_line = '<img src=\"{}\"> {} <br/>'.format(video_path, text)\n",
        "        html += html_line\n",
        "    return display.HTML(html)\n",
        "\n",
        "    \n",
        "def convert_video2gif(video_path, output_gif_path, num_samples=16):\n",
        "    frames = (\n",
        "        towhee.glob(video_path)\n",
        "              .video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': num_samples})\n",
        "              .to_list()[0]\n",
        "    )\n",
        "    imgs = [Image.fromarray(frame) for frame in frames]\n",
        "    imgs[0].save(fp=output_gif_path, format='GIF', append_images=imgs[1:], save_all=True, loop=0)\n",
        "\n",
        "\n",
        "def display_gifs_from_video(video_path_list, text_list, tmpdirname = './tmp_gifs'):\n",
        "    Path(tmpdirname).mkdir(exist_ok=True)\n",
        "    gif_path_list = []\n",
        "    for video_path in video_path_list:\n",
        "        video_name = str(Path(video_path).name).split('.')[0]\n",
        "        gif_path = Path(tmpdirname) / (video_name + '.gif')\n",
        "        convert_video2gif(video_path, gif_path)\n",
        "        gif_path_list.append(gif_path)\n",
        "    return display_gif(gif_path_list, text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6imosALM04pX"
      },
      "outputs": [],
      "source": [
        "sample_show_df = sample_df[:3]\n",
        "video_path_list = sample_show_df['video_path'].to_list()\n",
        "text_list = sample_show_df['sentence'].to_list()\n",
        "tmpdirname = './tmp_gifs'\n",
        "display_gifs_from_video(video_path_list, text_list, tmpdirname=tmpdirname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GGKA2-N2AaH"
      },
      "outputs": [],
      "source": [
        "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
        "\n",
        "connections.connect(host='127.0.0.1', port='19530')\n",
        "\n",
        "def create_milvus_collection(collection_name, dim):\n",
        "    if utility.has_collection(collection_name):\n",
        "        utility.drop_collection(collection_name)\n",
        "    \n",
        "    fields = [\n",
        "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
        "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
        "    ]\n",
        "    schema = CollectionSchema(fields=fields, description='video retrieval')\n",
        "    collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "    # create IVF_FLAT index for collection.\n",
        "    index_params = {\n",
        "        'metric_type':'L2', #IP\n",
        "        'index_type':\"IVF_FLAT\",\n",
        "        'params':{\"nlist\":2048}\n",
        "    }\n",
        "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "    return collection\n",
        "\n",
        "collection = create_milvus_collection('text_video_retrieval', 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_qmdQi42uY-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import towhee\n",
        "\n",
        "device = 'cuda:0'\n",
        "device = 'cpu'\n",
        "# For the first time you run this line, \n",
        "# it will take some time \n",
        "# because towhee will download operator with weights on backend.\n",
        "dc = (\n",
        "    towhee.read_csv(test_sample_csv_path)\n",
        "      .runas_op['video_id', 'id'](func=lambda x: int(x[-4:]))\n",
        "      .video_decode.ffmpeg['video_path', 'frames'](sample_type='uniform_temporal_subsample', args={'num_samples': 12})\n",
        "      .runas_op['frames', 'frames'](func=lambda x: [y for y in x])\n",
        "      .video_text_embedding.clip4clip['frames', 'vec'](model_name='clip_vit_b32', modality='video')\n",
        "      .to_milvus['id', 'vec'](collection=collection, batch=30)\n",
        ")\n",
        "print('Total number of inserted data is {}.'.format(collection.num_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2XgYH03XcJ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'\n",
        "dc = (\n",
        "    towhee.read_csv(test_sample_csv_path).unstream()\n",
        "      .video_text_embedding.clip4clip['sentence','text_vec'](model_name='clip_vit_b32', modality='text')\n",
        "      .milvus_search['text_vec', 'top10_raw_res'](collection='text_video_retrieval', limit=10)\n",
        "      .runas_op['video_id', 'ground_truth'](func=lambda x : [int(x[-4:])])\n",
        "      .runas_op['top10_raw_res', 'top1'](func=lambda res: [x.id for i, x in enumerate(res) if i < 1])\n",
        "      .runas_op['top10_raw_res', 'top5'](func=lambda res: [x.id for i, x in enumerate(res) if i < 5])\n",
        "      .runas_op['top10_raw_res', 'top10'](func=lambda res: [x.id for i, x in enumerate(res) if i < 10])\n",
        ")\n",
        "\n",
        "dc.select['video_id', 'sentence', 'ground_truth', 'top10_raw_res', 'top1', 'top5', 'top10']().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViSp0_sk3UcC"
      },
      "outputs": [],
      "source": [
        "benchmark = (\n",
        "    dc.with_metrics(['mean_hit_ratio',])\n",
        "        .evaluate['ground_truth', 'top1'](name='recall_at_1')\n",
        "        .evaluate['ground_truth', 'top5'](name='recall_at_5')\n",
        "        .evaluate['ground_truth', 'top10'](name='recall_at_10')\n",
        "        .report()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBIS7hwP3UcD"
      },
      "outputs": [],
      "source": [
        "import gradio\n",
        "import towhee.models.clip4clip\n",
        "\n",
        "device = 'cuda:0'\n",
        "collection='text_video_retrieval'\n",
        "show_num = 3\n",
        "with towhee.api() as api:\n",
        "    milvus_search_function = (\n",
        "         api.clip4clip(model_name='clip_vit_b32', modality='text', device=device)\n",
        "            .milvus_search(collection=collection, limit=show_num)\n",
        "            .runas_op(func=lambda res: [os.path.join(raw_video_path, 'video' + str(x.id) + '.mp4') for x in res])\n",
        "            .as_function()\n",
        "    )\n",
        "\n",
        "interface = gradio.Interface(milvus_search_function, \n",
        "                             inputs=[gradio.Textbox()],\n",
        "                             outputs=[gradio.Video(format='mp4') for _ in range(show_num)]\n",
        "                            )\n",
        "\n",
        "interface.launch(inline=True, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW9MNQjA3UcF"
      },
      "source": [
        "# Towhee text-image inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIugAWHf3UcG"
      },
      "outputs": [],
      "source": [
        "# for video in os.listdir(\"../AIChallenge_data/KeyFrames\"):\n",
        "#     fix_frame_df = pd.read_csv(os.path.join(\"../AIChallenge_data/Fix_KeyFrames/\",video +\".csv\"),names=[\"img\",\"frame\"])\n",
        "#     for i in range(len(fix_frame_df)):\n",
        "#         img_path_df = img_path_df.append({\"img_path\":os.path.join(\"KeyFrames\",video,fix_frame_df.iloc[i][\"img\"]),\n",
        "#         \"video_id\":video,\"frame\":fix_frame_df.iloc[i][\"frame\"]},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlyo0NQ93UcH"
      },
      "outputs": [],
      "source": [
        "# img_path_df.to_csv(\"key_frame_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtn07IS-3UcM"
      },
      "outputs": [],
      "source": [
        "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
        "\n",
        "connections.connect(host='127.0.0.1', port='19530')\n",
        "\n",
        "def create_milvus_collection(collection_name, dim):\n",
        "    if utility.has_collection(collection_name):\n",
        "        utility.drop_collection(collection_name)\n",
        "    \n",
        "    fields = [\n",
        "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
        "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
        "    ]\n",
        "    schema = CollectionSchema(fields=fields, description='text image search')\n",
        "    collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "    # create IVF_FLAT index for collection.\n",
        "    index_params = {\n",
        "        'metric_type':'L2',\n",
        "        'index_type':\"IVF_FLAT\",\n",
        "        'params':{\"nlist\":512}\n",
        "    }\n",
        "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "    return collection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"KeyFrames\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "NZRht4VXRDhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/KeyFrames ."
      ],
      "metadata": {
        "id": "uuebue14RL0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf-2G4Qn3UcN",
        "outputId": "7ec603a4-fbcb-49b1-f00d-1e7cea28dad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                        img_path   video_id  false_frame  frame\n",
              "0            0  KeyFrames\\C00_V0000\\000000.jpg  C00_V0000            0      0\n",
              "1            1  KeyFrames\\C00_V0000\\000096.jpg  C00_V0000           96     96\n",
              "2            2  KeyFrames\\C00_V0000\\000206.jpg  C00_V0000          206    206\n",
              "3            3  KeyFrames\\C00_V0000\\000378.jpg  C00_V0000          378    378\n",
              "4            4  KeyFrames\\C00_V0000\\000545.jpg  C00_V0000          545    545\n",
              "...        ...                             ...        ...          ...    ...\n",
              "226631  226631  KeyFrames\\C02_V0199\\051029.jpg  C02_V0199        51029  51029\n",
              "226632  226632  KeyFrames\\C02_V0199\\051040.jpg  C02_V0199        51040  51040\n",
              "226633  226633  KeyFrames\\C02_V0199\\051200.jpg  C02_V0199        51200  51200\n",
              "226634  226634  KeyFrames\\C02_V0199\\051360.jpg  C02_V0199        51360  51360\n",
              "226635  226635  KeyFrames\\C02_V0199\\051520.jpg  C02_V0199        51520  51520\n",
              "\n",
              "[226636 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "      <th>video_id</th>\n",
              "      <th>false_frame</th>\n",
              "      <th>frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000000.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000096.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000206.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000378.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>378</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000545.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>545</td>\n",
              "      <td>545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226631</th>\n",
              "      <td>226631</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051029.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51029</td>\n",
              "      <td>51029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226632</th>\n",
              "      <td>226632</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051040.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51040</td>\n",
              "      <td>51040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226633</th>\n",
              "      <td>226633</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051200.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51200</td>\n",
              "      <td>51200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226634</th>\n",
              "      <td>226634</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051360.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51360</td>\n",
              "      <td>51360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226635</th>\n",
              "      <td>226635</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051520.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51520</td>\n",
              "      <td>51520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226636 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_keyframes = pd.read_csv('key_frame_df.csv',index_col=0)\n",
        "df_keyframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGcqXYbk3UcO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from towhee._types.image import Image\n",
        "\n",
        "id_img = df_keyframes.set_index('id')['img_path'].to_dict()\n",
        "def read_images(results):\n",
        "    imgs = []\n",
        "    for re in results:\n",
        "        # print(re)\n",
        "        path = id_img[re.id]\n",
        "        imgs.append(path)\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Faiss local and colab"
      ],
      "metadata": {
        "id": "lQfo70kTTre0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create image embeddings and build index\n",
        "(\n",
        "    towhee.read_csv('key_frame_df.csv')\n",
        "          .runas_op['id', 'id'](func=lambda x: int(x))\n",
        "          .set_parallel(4)\n",
        "          .image_decode['img_path', 'img']()\n",
        "          .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
        "          .tensor_normalize['vec','vec']()\n",
        "          .to_faiss[('id', 'vec')](findex='./index.bin')\n",
        ")"
      ],
      "metadata": {
        "id": "6nrtm_shTT0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q31iZtz3UcS"
      },
      "outputs": [],
      "source": [
        "queries = {}\n",
        "with open(\"./query.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        query_name = line.split(\"//\")[0]\n",
        "        query = line.split(\"//\")[1]\n",
        "        queries[query_name] = query"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milvus local machine only"
      ],
      "metadata": {
        "id": "y3xS4t6MTjsO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsBDd7TP3UcP"
      },
      "outputs": [],
      "source": [
        "collection = create_milvus_collection('text_image_search', 512)\n",
        "collection = Collection('text_image_challenge_search')\n",
        "dc = (\n",
        "    towhee.read_csv('key_frame_df.csv')\n",
        "      .runas_op['id', 'id'](func=lambda x: int(x))\n",
        "      .set_parallel(4)\n",
        "      .image_decode['img_path', 'img']()\n",
        "      .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
        "      .tensor_normalize['vec','vec']()\n",
        "      .to_milvus['id', 'vec'](collection='text_image_search', batch=100)\n",
        "      \n",
        ")\n",
        "print('Total number of inserted data is {}.'.format(collection.num_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wTlbBQr3UcS"
      },
      "outputs": [],
      "source": [
        "for i in range(26,len(queries.keys())):\n",
        "  key = list(queries.keys())[i]\n",
        "  (\n",
        "      towhee.dc['text']([queries[key]])\n",
        "        .image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32', modality='text')\n",
        "        .tensor_normalize['vec','vec']()\n",
        "        .milvus_search['vec', 'result'](collection=collection, limit=100)\n",
        "        .runas_op['result', 'result_img'](func=read_images)\n",
        "        .select['result_img']()\n",
        "        .to_csv(key+\".csv\")      \n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate query pack"
      ],
      "metadata": {
        "id": "JKCwm9mCR0wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://download039.fshare.vn/dl/hcL280KJz4ZEVrp8deuD4jastfEuPfRzeC8zbb7h6IC2mQKY7hd-pH7diN5uOkh2AbN4RiIRTjrXwh2C/query-pack-0.zip\n",
        "# !wget https://download039.fshare.vn/dl/kQpla+QWiPVNJn72Xh4ZWETidn2Wt4oq7Uty-VfCscQA2pL8-kexe9VU6jYwCgcrENcyy47XaofvjKCc/query-pack-1.zip\n",
        "# !wget https://download022.fshare.vn/dl/kWomGkkLX4UelE4fupVCUFlJmUkqiAVk56-42tZQ1e2+5VFjMMn78TTgvXzI7bElS1KnWpOw3EZ-JR+P/query-pack-2.zip"
      ],
      "metadata": {
        "id": "arimc3JxR4zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip query-pack-0.zip -d query-pack\n",
        "# !unzip query-pack-1.zip -d query-pack\n",
        "# !unzip query-pack-2.zip -d query-pack"
      ],
      "metadata": {
        "id": "CR3dzcrSSQtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf query-pack-0.zip\n",
        "# !rm -rf query-pack-1.zip\n",
        "# !rm -rf query-pack-2.zip"
      ],
      "metadata": {
        "id": "TFiZG871SitP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KOJT8803UcT"
      },
      "outputs": [],
      "source": [
        "# Only run this cell the first time you run this notebook to create a folder of english version of the queries\n",
        "# Then you can comment this cell to only run the cell below to read that folder. \n",
        "query_dir = \"D:\\GitHub\\AIChallenge_data\\query-pack-0\\query-pack-0\"\n",
        "en_query_dir = os.path.join(os.path.dirname(query_dir),\"en_\"+ query_dir.split(\"\\\\\")[-1])\n",
        "try:\n",
        "    os.mkdir(en_query_dir)\n",
        "except:\n",
        "    pass\n",
        "list_queries_file = os.listdir(query_dir)\n",
        "en_queries = []\n",
        "for query in list_queries_file:\n",
        "    with open(os.path.join(query_dir,query),\"r\",encoding='utf8') as f:\n",
        "        with open(os.path.join(en_query_dir,\"en_\" + query),\"w\",encoding='utf8') as f_out:\n",
        "            read_line = f.readline()\n",
        "            vi2en_text = translate_vi2en(read_line)\n",
        "            f_out.write(vi2en_text)\n",
        "            en_queries.append(vi2en_text)\n",
        "\n",
        "en_queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZBWcflX3UcU",
        "outputId": "6f19e55d-c3f8-4da1-a266-c89ea96da4ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The news of a match of Vietnamese football team. Vietnamese players are celebrating after a goal. This is not the national team but the U19 team. The goal that lifted the score to 2-0 came from a close-fitting header. Opponents of Vietnam U19 are Brunei U19.',\n",
              " 'A favorite recreational activity of young people. Flying kites in the suburbs of Ho Chi Minh City. In the picture there is a giant kite in the shape of a squid. On the same day was the launch of Chau Doc Bridge across the Hau parallel.',\n",
              " 'A team car race, consisting of adults and children. These cars do not have engines, instead they are pushed by the parents. At the starting line, there are 3 people dressed up as zebras. This newscast was broadcast on the day that the day before was the Swiss National Day.',\n",
              " 'A zoo in China with many different animals. In the frame there are 2 hippos. One of the 2 is drinking water. In addition to hippos, the zoo also has elephants and raccoons.',\n",
              " 'A picture of U.S. President Joe Biden. The U.S. President is wearing black glasses. It was the front page of an article. The Vietnamese title read: The U.S. may waive tariffs on solar cells from Vietnam. It was an article from Reuters news agency.',\n",
              " 'The artist is coloring the mask meticulously. Around him are a lot of masks. The artist wears very simple honeycomb slippers. This type of mask is called a Mid-Autumn paper mask.',\n",
              " 'The scene contains 3-4 people in shiny outfits. Before that is the image of an army lined up, which resembles a ritual. These are members of the Swiss Guard. They are taking the oath to protect the Pope.',\n",
              " 'Picture of a man holding a large bouquet of flowers. He is at a flower shop. This shop is called “Flower box\". This image is in a reportage about the price of roses on Valentine\\'s Day.',\n",
              " 'A man is playing the saxophone. Behind him is another man playing the viola. There is also a drummer, and a piano. The four instruments form a jazz quartet. This is part of the event to strengthen the friendship between the group of V4 countries with Vietnam.',\n",
              " 'A statue of a famous historical figure. This figure is riding a horse. The Vietnamese title reads: “Tham đinh tuong Đuc Thanh Tran o Ho May, Vung Tau\". The statue is bronze yellow.']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_dir = \"D:\\GitHub\\AIChallenge_data\\query-pack-0\\en_query-pack-0\"\n",
        "list_queries_file = os.listdir(query_dir)\n",
        "en_queries = []\n",
        "for query in list_queries_file:\n",
        "    with open(os.path.join(query_dir,query),\"r\",encoding='utf8') as f:\n",
        "        read_line = f.readline()\n",
        "        en_queries.append(read_line)\n",
        "\n",
        "en_queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlGg04oM3UcU"
      },
      "outputs": [],
      "source": [
        "collection = Collection(\"text_image_search\")\n",
        "(\n",
        "      towhee.dc['text'](en_queries)\n",
        "        .image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32', modality='text')\n",
        "        .tensor_normalize['vec','vec']()\n",
        "        .milvus_search['vec', 'result'](collection=collection, limit=100)\n",
        "        .runas_op['result', 'result_img'](func=read_images)\n",
        "        .select['text','result_img']()\n",
        "        .to_csv(\"test.csv\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSUCI3qw3UcV"
      },
      "outputs": [],
      "source": [
        "# The result will be save in a folder name \"result\" in the folder contain queries pack\n",
        "from ast import literal_eval\n",
        "df = pd.read_csv(\"test.csv\")\n",
        "df.result_img =df.result_img.apply(literal_eval)\n",
        "\n",
        "result_query_dir = os.path.join(os.path.dirname(query_dir),\"result\")\n",
        "try:\n",
        "    os.mkdir(result_query_dir)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range(len(list_queries_file)):\n",
        "    with open(os.path.join(result_query_dir,\"{}.csv\".format(list_queries_file[i].split(\".\")[0].replace(\"en_\",\"\"))),\"w\") as f:\n",
        "        list_img = df[\"result_img\"][i]\n",
        "        for img in list_img:\n",
        "            video_id = img.split(\"\\\\\")[-2]\n",
        "            false_frame = img.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "            real_frame = df_keyframes[df_keyframes.false_frame == int(false_frame)][video_id==df_keyframes.video_id].frame.values[0]\n",
        "            f.write(video_id + \".mp4, \" + str(false_frame) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjSAOMra3UcW"
      },
      "source": [
        "# Calculate score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn-thwdH3UcX",
        "outputId": "aa9da26a-90e5-4da2-83a5-469f5ed06f7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6.4"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Use this link if it's still available to check the queries results\n",
        "# Link: http://128.199.178.135:4567/?fbclid=IwAR0rtcLToubngq62z765Ee-gp-2Wxl_BEp-cASrUkEo1ujn7ZnZLjoRFRXE\n",
        "# put your rank of the 10 queries here\n",
        "#----------------------------------------\n",
        "rank = [18,5,1,1,2,33,101,63,1,13]\n",
        "#----------------------------------------\n",
        "\n",
        "accept_rank = [1,5,20,50,100]\n",
        "score = []\n",
        "for i in range(len(rank)):\n",
        "    for j in range(len(accept_rank)):\n",
        "        score.append(1 if rank[i] <= accept_rank[j] else 0)\n",
        "\n",
        "total_score = np.sum(score) / 5\n",
        "total_score\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 ('env4ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f684d485204dfdeef2abe219ca21370c20995e9c270e0d9ebbd2a2aeed1acfbd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}