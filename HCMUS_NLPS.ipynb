{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranPhu1999/HCMUS-NLPS-AIChallenge/blob/Phu/HCMUS_NLPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7p7iuQEwbcY"
      },
      "source": [
        "# Tham khảo\n",
        "- Paper: https://paperswithcode.com/paper/frozen-in-time-a-joint-video-and-image\n",
        "- Towee repo: https://github.com/towhee-io/towhee\n",
        "- Video-text retrival: https://codelabs.towhee.io/how-to-build-a-text-video-retrieval-engine/index#1\n",
        "- Similar video: https://codelabs.towhee.io/build-a-reverse-video-search-engine-in-minutes/index#0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ANjUARZ85tTx",
        "outputId": "5e4a61a9-dc1a-40ce-95c5-6088b4010dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "id": "ok0V5sHlMTor",
        "outputId": "8b840054-53f6-47fd-9e1b-77232ebcb1da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V00.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V01.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V01.zip\n",
        "# !wget https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V01.zip"
      ],
      "metadata": {
        "id": "fvg110Sl5Nu8",
        "outputId": "60cabcc4-61f7-45e6-c246-8072c1a65720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-30 08:02:21--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V00.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.52, 125.212.206.48\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9207919383 (8.6G) [application/zip]\n",
            "Saving to: ‘KeyFramesC01_V00.zip’\n",
            "\n",
            "KeyFramesC01_V00.zi 100%[===================>]   8.58G  12.8MB/s    in 15m 43s \n",
            "\n",
            "2022-10-30 08:18:06 (9.31 MB/s) - ‘KeyFramesC01_V00.zip’ saved [9207919383/9207919383]\n",
            "\n",
            "--2022-10-30 08:18:06--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V00.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11260966214 (10G) [application/zip]\n",
            "Saving to: ‘KeyFramesC02_V00.zip’\n",
            "\n",
            "KeyFramesC02_V00.zi 100%[===================>]  10.49G  12.8MB/s    in 14m 7s  \n",
            "\n",
            "2022-10-30 08:32:14 (12.7 MB/s) - ‘KeyFramesC02_V00.zip’ saved [11260966214/11260966214]\n",
            "\n",
            "--2022-10-30 08:32:14--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC00_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4561839380 (4.2G) [application/zip]\n",
            "Saving to: ‘KeyFramesC00_V01.zip’\n",
            "\n",
            "KeyFramesC00_V01.zi 100%[===================>]   4.25G  12.7MB/s    in 5m 50s  \n",
            "\n",
            "2022-10-30 08:38:06 (12.4 MB/s) - ‘KeyFramesC00_V01.zip’ saved [4561839380/4561839380]\n",
            "\n",
            "--2022-10-30 08:38:06--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC01_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.52, 125.212.206.48\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4285711517 (4.0G) [application/zip]\n",
            "Saving to: ‘KeyFramesC01_V01.zip’\n",
            "\n",
            "KeyFramesC01_V01.zi 100%[===================>]   3.99G  12.4MB/s    in 5m 26s  \n",
            "\n",
            "2022-10-30 08:43:33 (12.5 MB/s) - ‘KeyFramesC01_V01.zip’ saved [4285711517/4285711517]\n",
            "\n",
            "--2022-10-30 08:43:34--  https://s3-north.viettelidc.com.vn/aic2022-public-data/KeyFramesC02_V01.zip\n",
            "Resolving s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)... 125.212.206.48, 125.212.206.52\n",
            "Connecting to s3-north.viettelidc.com.vn (s3-north.viettelidc.com.vn)|125.212.206.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8975732543 (8.4G) [application/zip]\n",
            "Saving to: ‘KeyFramesC02_V01.zip’\n",
            "\n",
            "KeyFramesC02_V01.zi 100%[===================>]   8.36G  12.9MB/s    in 11m 16s \n",
            "\n",
            "2022-10-30 08:54:51 (12.7 MB/s) - ‘KeyFramesC02_V01.zip’ saved [8975732543/8975732543]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip KeyFramesC00_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC00_V00.zip\n",
        "# !unzip KeyFramesC01_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC01_V00.zip\n",
        "# !unzip KeyFramesC02_V00.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC02_V00.zip\n",
        "# !unzip KeyFramesC00_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC00_V01.zip\n",
        "# !unzip KeyFramesC01_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC01_V01.zip\n",
        "# !unzip KeyFramesC02_V01.zip -d KeyFrames\n",
        "# !rm -rf KeyFramesC02_V01.zip"
      ],
      "metadata": {
        "id": "lZGCvhMCMWdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "len(glob.glob(\"./KeyFrames/*/*.jpg\"))"
      ],
      "metadata": {
        "id": "qPMCpuK3O9Qw",
        "outputId": "e9ed03b9-b274-4111-ebe7-affad7c9f696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "226636"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n",
        "%ll"
      ],
      "metadata": {
        "id": "via9A6NTKald",
        "outputId": "03fce086-ba4f-4eaa-9594-69ee00ea153e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n",
            "total 14999\n",
            "-rw------- 1 root 15353881 Oct 30 09:10 key_frame_df.csv\n",
            "-rw------- 1 root      112 Oct 30 09:07 requirements.txt\n",
            "drwx------ 2 root     4096 Oct 30 09:18 \u001b[0m\u001b[01;34mvi_en_translate\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAiErZ4uzTj"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mo7fV_2K3Ubs"
      },
      "outputs": [],
      "source": [
        "import towhee\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MyLrGOr3Ubv"
      },
      "source": [
        "# Vietnamese Engslish Translate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"vi_en_translate\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "IWk8h8YZLHq6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd vi_en_translate\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/pytorch_model.bin\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/config.json\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/sentencepiece.bpe.model\n",
        "!wget https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/tf_model.h5\n",
        "%cd .."
      ],
      "metadata": {
        "id": "_1wbk9nCKkqo",
        "outputId": "55644f24-a55b-45a0-9eb7-9591d2a03e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS/vi_en_translate\n",
            "--2022-10-30 09:16:31--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 52.3.185.208, 34.227.129.17, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.3.185.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/245f08542f8b87d4d8721912ba3ae7d02feb5b72943d759135f4d551d4f32455?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1667380592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvMjQ1ZjA4NTQyZjhiODdkNGQ4NzIxOTEyYmEzYWU3ZDAyZmViNWI3Mjk0M2Q3NTkxMzVmNGQ1NTFkNGYzMjQ1NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnB5dG9yY2hfbW9kZWwuYmluJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNTkyfX19XX0_&Signature=yVjattFQ3GcSzicAl-H3aldoA78s9hsIMSxl2Be1uAyqvFe8rQlXkfwJHq-3PmVuj-2FR39Dfmfeww06SAFR4ChJaMCDfss6RbvURS5a-ZvkLhaf87~zPJrzUkOQExwwvxAomtjuPRuaHEvvbCMNdrXStxBqz2gc132HQK4-ul5fipQGBsBCykUGq88FtFDTEY2zlGitWpxONkBIQevzGTSs-frxCVKv-IfKTJQRsZtwbXqaquKtLlsF0~WHrpu6gKxURG7cyy-dDkcvMe1Xb8dF72rj49A52yafYq-x2yl1XWmoPe8m232UBEREz43sNYNEb83v1ImrF0FL13tOVg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:16:32--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/245f08542f8b87d4d8721912ba3ae7d02feb5b72943d759135f4d551d4f32455?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22&Expires=1667380592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvMjQ1ZjA4NTQyZjhiODdkNGQ4NzIxOTEyYmEzYWU3ZDAyZmViNWI3Mjk0M2Q3NTkxMzVmNGQ1NTFkNGYzMjQ1NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnB5dG9yY2hfbW9kZWwuYmluJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNTkyfX19XX0_&Signature=yVjattFQ3GcSzicAl-H3aldoA78s9hsIMSxl2Be1uAyqvFe8rQlXkfwJHq-3PmVuj-2FR39Dfmfeww06SAFR4ChJaMCDfss6RbvURS5a-ZvkLhaf87~zPJrzUkOQExwwvxAomtjuPRuaHEvvbCMNdrXStxBqz2gc132HQK4-ul5fipQGBsBCykUGq88FtFDTEY2zlGitWpxONkBIQevzGTSs-frxCVKv-IfKTJQRsZtwbXqaquKtLlsF0~WHrpu6gKxURG7cyy-dDkcvMe1Xb8dF72rj49A52yafYq-x2yl1XWmoPe8m232UBEREz43sNYNEb83v1ImrF0FL13tOVg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.109, 18.64.174.43, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1794247767 (1.7G) [application/zip]\n",
            "Saving to: ‘pytorch_model.bin’\n",
            "\n",
            "pytorch_model.bin   100%[===================>]   1.67G  46.9MB/s    in 38s     \n",
            "\n",
            "2022-10-30 09:17:10 (45.1 MB/s) - ‘pytorch_model.bin’ saved [1794247767/1794247767]\n",
            "\n",
            "--2022-10-30 09:17:10--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1466 (1.4K) [text/plain]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-30 09:17:10 (101 MB/s) - ‘config.json’ saved [1466/1466]\n",
            "\n",
            "--2022-10-30 09:17:10--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/sentencepiece.bpe.model\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/acd6ee71173d8414b78c0a961d8913c37e6ff78988a7282d69a9242156042063?response-content-disposition=attachment%3B%20filename%3D%22sentencepiece.bpe.model%22&Expires=1667380631&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvYWNkNmVlNzExNzNkODQxNGI3OGMwYTk2MWQ4OTEzYzM3ZTZmZjc4OTg4YTcyODJkNjlhOTI0MjE1NjA0MjA2Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNlbnRlbmNlcGllY2UuYnBlLm1vZGVsJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMxfX19XX0_&Signature=nL3NnM59yX6-4pHtriSRZETJf4oPyIBpTbXi-uSF3~f54srp7yinw~HBysuJEs99jGrdbWF-hcTRY4i10njfPIX4jcSbxpECnzfvJAJ~zyy68EbQ8GtpoPLW0lEGfZ5ScUfzNthvAEFN~VWQDofIIs2tVDjFbTZNH~2uzh1Cpr03veZdUoijEBw4ka82kvAhYVCYg0QKyr8sYxMPPJTwZ38JsnGaL4hYFI6nWZF8MhsKUdqA0OjT1B9EsmTj7~4u8U7WscitWO7DVxXWpyBl2LkYY5~uBDqzNu9T-TOyxQtpmDV9b0VR3mbaSJKLQV20S8kA38jH5WzzQDoiiV99Ww__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:17:11--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/acd6ee71173d8414b78c0a961d8913c37e6ff78988a7282d69a9242156042063?response-content-disposition=attachment%3B%20filename%3D%22sentencepiece.bpe.model%22&Expires=1667380631&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvYWNkNmVlNzExNzNkODQxNGI3OGMwYTk2MWQ4OTEzYzM3ZTZmZjc4OTg4YTcyODJkNjlhOTI0MjE1NjA0MjA2Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNlbnRlbmNlcGllY2UuYnBlLm1vZGVsJTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMxfX19XX0_&Signature=nL3NnM59yX6-4pHtriSRZETJf4oPyIBpTbXi-uSF3~f54srp7yinw~HBysuJEs99jGrdbWF-hcTRY4i10njfPIX4jcSbxpECnzfvJAJ~zyy68EbQ8GtpoPLW0lEGfZ5ScUfzNthvAEFN~VWQDofIIs2tVDjFbTZNH~2uzh1Cpr03veZdUoijEBw4ka82kvAhYVCYg0QKyr8sYxMPPJTwZ38JsnGaL4hYFI6nWZF8MhsKUdqA0OjT1B9EsmTj7~4u8U7WscitWO7DVxXWpyBl2LkYY5~uBDqzNu9T-TOyxQtpmDV9b0VR3mbaSJKLQV20S8kA38jH5WzzQDoiiV99Ww__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1879553 (1.8M) [binary/octet-stream]\n",
            "Saving to: ‘sentencepiece.bpe.model’\n",
            "\n",
            "sentencepiece.bpe.m 100%[===================>]   1.79M  11.1MB/s    in 0.2s    \n",
            "\n",
            "2022-10-30 09:17:11 (11.1 MB/s) - ‘sentencepiece.bpe.model’ saved [1879553/1879553]\n",
            "\n",
            "--2022-10-30 09:17:11--  https://huggingface.co/vinai/vinai-translate-vi2en/resolve/main/tf_model.h5\n",
            "Resolving huggingface.co (huggingface.co)... 34.227.129.17, 52.3.185.208, 2600:1f18:147f:e850:db19:5c51:ec6e:ddca, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.227.129.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/9188bf7fa76a84bb37c6dabcb73ad57c3b4a799aa4c3ea8bcb38b49029444957?response-content-disposition=attachment%3B%20filename%3D%22tf_model.h5%22&Expires=1667380632&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvOTE4OGJmN2ZhNzZhODRiYjM3YzZkYWJjYjczYWQ1N2MzYjRhNzk5YWE0YzNlYThiY2IzOGI0OTAyOTQ0NDk1Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmX21vZGVsLmg1JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMyfX19XX0_&Signature=JZEZLWghy5C03mS7IboX7jRip0Gq8w9eG9nccmhZ33smFCJp~xLLnvLYqCxJEOFybk4MXagbCu7K9RY9xX5G3in-v7kUNP8ayDiGSzLx1bfb3cGmbn-cwerMCjckV3KuAscQOCZCMQCRYAXfMz5hvXZMW1Ihf9An9lQxsVNEs9rAVwdT2TYCe0ZV1gtniIVjguz7M3vRItEWSBcAw~JoR9htgNpQ80fSH7DO79Sz3xMcqBNL-q-YTEkkb-3Z49~dAxNhTTEui~hAjN87E3z3AaNJTwJY18J6RHkoSs9fnJnbSA5qpOhZUgXE-rq36JYfFYwEXrsWcOPbntSBnfsAUw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-30 09:17:11--  https://cdn-lfs.huggingface.co/repos/ff/86/ff8651c4ac410bb102bd28be9525daee7edc5c7eb6f4eed159926ce0da08f1b8/9188bf7fa76a84bb37c6dabcb73ad57c3b4a799aa4c3ea8bcb38b49029444957?response-content-disposition=attachment%3B%20filename%3D%22tf_model.h5%22&Expires=1667380632&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZmLzg2L2ZmODY1MWM0YWM0MTBiYjEwMmJkMjhiZTk1MjVkYWVlN2VkYzVjN2ViNmY0ZWVkMTU5OTI2Y2UwZGEwOGYxYjgvOTE4OGJmN2ZhNzZhODRiYjM3YzZkYWJjYjczYWQ1N2MzYjRhNzk5YWE0YzNlYThiY2IzOGI0OTAyOTQ0NDk1Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmX21vZGVsLmg1JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY3MzgwNjMyfX19XX0_&Signature=JZEZLWghy5C03mS7IboX7jRip0Gq8w9eG9nccmhZ33smFCJp~xLLnvLYqCxJEOFybk4MXagbCu7K9RY9xX5G3in-v7kUNP8ayDiGSzLx1bfb3cGmbn-cwerMCjckV3KuAscQOCZCMQCRYAXfMz5hvXZMW1Ihf9An9lQxsVNEs9rAVwdT2TYCe0ZV1gtniIVjguz7M3vRItEWSBcAw~JoR9htgNpQ80fSH7DO79Sz3xMcqBNL-q-YTEkkb-3Z49~dAxNhTTEui~hAjN87E3z3AaNJTwJY18J6RHkoSs9fnJnbSA5qpOhZUgXE-rq36JYfFYwEXrsWcOPbntSBnfsAUw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.64.174.106, 18.64.174.110, 18.64.174.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.64.174.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1794265048 (1.7G) [application/octet-stream]\n",
            "Saving to: ‘tf_model.h5’\n",
            "\n",
            "tf_model.h5         100%[===================>]   1.67G  51.3MB/s    in 50s     \n",
            "\n",
            "2022-10-30 09:18:01 (34.4 MB/s) - ‘tf_model.h5’ saved [1794265048/1794265048]\n",
            "\n",
            "/content/drive/MyDrive/Colab Notebooks/HCMUS_NLPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dFk642OM3Ubx"
      },
      "outputs": [],
      "source": [
        "dict_map = {\n",
        "    \"òa\": \"oà\",\"Òa\": \"Oà\",\"ÒA\": \"OÀ\",\"óa\": \"oá\",\"Óa\": \"Oá\",\"ÓA\": \"OÁ\",\"ỏa\": \"oả\",\"Ỏa\": \"Oả\",\"ỎA\": \"OẢ\",\"õa\": \"oã\",\n",
        "    \"Õa\": \"Oã\",\"ÕA\": \"OÃ\",\"ọa\": \"oạ\",\"Ọa\": \"Oạ\",\"ỌA\": \"OẠ\",\"òe\": \"oè\",\"Òe\": \"Oè\",\"ÒE\": \"OÈ\",\"óe\": \"oé\",\"Óe\": \"Oé\",\n",
        "    \"ÓE\": \"OÉ\",\"ỏe\": \"oẻ\",\"Ỏe\": \"Oẻ\",\"ỎE\": \"OẺ\",\"õe\": \"oẽ\",\"Õe\": \"Oẽ\",\"ÕE\": \"OẼ\",\"ọe\": \"oẹ\",\"Ọe\": \"Oẹ\",\"ỌE\": \"OẸ\",\n",
        "    \"ùy\": \"uỳ\",\"Ùy\": \"Uỳ\",\"ÙY\": \"UỲ\",\"úy\": \"uý\",\"Úy\": \"Uý\",\"ÚY\": \"UÝ\",\"ủy\": \"uỷ\",\"Ủy\": \"Uỷ\",\"ỦY\": \"UỶ\",\"ũy\": \"uỹ\",\n",
        "    \"Ũy\": \"Uỹ\",\"ŨY\": \"UỸ\",\"ụy\": \"uỵ\",\"Ụy\": \"Uỵ\",\"ỤY\": \"UỴ\",\n",
        "    }\n",
        "\n",
        "def strip_accents(s):\n",
        "       return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                  if unicodedata.category(c) != 'Mn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5mS-5Nwm3Ubz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"./vi_en_translate/\", src_lang=\"vi_VN\")\n",
        "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"./vi_en_translate/\")\n",
        "\n",
        "def translate_vi2en(vi_text: str) -> str:\n",
        "    for i, j in dict_map.items():\n",
        "        vi_text = vi_text.replace(i, j)\n",
        "    input_ids = tokenizer_vi2en(vi_text, return_tensors=\"pt\").input_ids\n",
        "    output_ids = model_vi2en.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        top_k=100,\n",
        "        top_p=0.8,\n",
        "        decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "    en_text = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    en_text = \" \".join(en_text)\n",
        "    en_text = strip_accents(en_text)\n",
        "    en_text = en_text.replace(\"\\\\\",\"\")\n",
        "    return en_text\n",
        "\n",
        "# vi_text = \"Cô cho biết: trước giờ tôi không đến phòng tập công cộng, mà tập cùng giáo viên Yoga riêng hoặc tự tập ở nhà. Khi tập thể dục trong không gian riêng tư, tôi thoải mái dễ chịu hơn.\"\n",
        "# print(translate_vi2en(vi_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFrsqOE1wvoP"
      },
      "source": [
        "# Towhee text-video inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhuwMvBMvWhO"
      },
      "outputs": [],
      "source": [
        "# !curl -L https://github.com/towhee-io/examples/releases/download/data/text_video_search.zip -O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep6Mn3t0zR2s"
      },
      "outputs": [],
      "source": [
        "# Nếu chạy không được lệnh này thì ra ngoài folder rồi tự unzip\n",
        "# !unzip -q -o text_video_search.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtBQERZFzWcX"
      },
      "outputs": [],
      "source": [
        "# ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-BaMxTszcxW"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "\n",
        "# raw_video_path = './test_1k_compress' # 1k test video path.\n",
        "# test_csv_path = './MSRVTT_JSFUSION_test.csv' # 1k video caption csv.\n",
        "\n",
        "# test_sample_csv_path = './MSRVTT_JSFUSION_test_sample.csv'\n",
        "\n",
        "# sample_num = 1000 # you can change this sample_num to be smaller, so that this notebook will be faster.\n",
        "# test_df = pd.read_csv(test_csv_path)\n",
        "# print('length of all test set is {}'.format(len(test_df)))\n",
        "# sample_df = test_df.sample(sample_num, random_state=42)\n",
        "\n",
        "# sample_df['video_path'] = sample_df.apply(lambda x:os.path.join(raw_video_path, x['video_id']) + '.mp4', axis=1)\n",
        "\n",
        "# sample_df.to_csv(test_sample_csv_path)\n",
        "# print('random sample {} examples'.format(sample_num))\n",
        "\n",
        "# df = pd.read_csv(test_sample_csv_path)\n",
        "\n",
        "# df[['video_id', 'video_path', 'sentence']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjbavLhRzkoT"
      },
      "outputs": [],
      "source": [
        "# from IPython import display\n",
        "# from pathlib import Path\n",
        "# import towhee\n",
        "# from PIL import Image\n",
        "\n",
        "# def display_gif(video_path_list, text_list):\n",
        "#     html = ''\n",
        "#     for video_path, text in zip(video_path_list, text_list):\n",
        "#         html_line = '<img src=\"{}\"> {} <br/>'.format(video_path, text)\n",
        "#         html += html_line\n",
        "#     return display.HTML(html)\n",
        "\n",
        "    \n",
        "# def convert_video2gif(video_path, output_gif_path, num_samples=16):\n",
        "#     frames = (\n",
        "#         towhee.glob(video_path)\n",
        "#               .video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': num_samples})\n",
        "#               .to_list()[0]\n",
        "#     )\n",
        "#     imgs = [Image.fromarray(frame) for frame in frames]\n",
        "#     imgs[0].save(fp=output_gif_path, format='GIF', append_images=imgs[1:], save_all=True, loop=0)\n",
        "\n",
        "\n",
        "# def display_gifs_from_video(video_path_list, text_list, tmpdirname = './tmp_gifs'):\n",
        "#     Path(tmpdirname).mkdir(exist_ok=True)\n",
        "#     gif_path_list = []\n",
        "#     for video_path in video_path_list:\n",
        "#         video_name = str(Path(video_path).name).split('.')[0]\n",
        "#         gif_path = Path(tmpdirname) / (video_name + '.gif')\n",
        "#         convert_video2gif(video_path, gif_path)\n",
        "#         gif_path_list.append(gif_path)\n",
        "#     return display_gif(gif_path_list, text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6imosALM04pX"
      },
      "outputs": [],
      "source": [
        "# sample_show_df = sample_df[:3]\n",
        "# video_path_list = sample_show_df['video_path'].to_list()\n",
        "# text_list = sample_show_df['sentence'].to_list()\n",
        "# tmpdirname = './tmp_gifs'\n",
        "# display_gifs_from_video(video_path_list, text_list, tmpdirname=tmpdirname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GGKA2-N2AaH"
      },
      "outputs": [],
      "source": [
        "# from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
        "\n",
        "# connections.connect(host='127.0.0.1', port='19530')\n",
        "\n",
        "# # def create_milvus_collection(collection_name, dim):\n",
        "# #     if utility.has_collection(collection_name):\n",
        "# #         utility.drop_collection(collection_name)\n",
        "    \n",
        "# #     fields = [\n",
        "# #     FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
        "# #     FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
        "# #     ]\n",
        "# #     schema = CollectionSchema(fields=fields, description='video retrieval')\n",
        "# #     collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "# #     # create IVF_FLAT index for collection.\n",
        "# #     index_params = {\n",
        "# #         'metric_type':'L2', #IP\n",
        "# #         'index_type':\"IVF_FLAT\",\n",
        "# #         'params':{\"nlist\":2048}\n",
        "# #     }\n",
        "# #     collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "# #     return collection\n",
        "\n",
        "# # collection = create_milvus_collection('text_video_retrieval', 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_qmdQi42uY-"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import towhee\n",
        "\n",
        "# # # device = 'cuda:0'\n",
        "# # # device = 'cpu'\n",
        "# # # For the first time you run this line, \n",
        "# # # it will take some time \n",
        "# # # because towhee will download operator with weights on backend.\n",
        "# # dc = (\n",
        "# #     towhee.read_csv(test_sample_csv_path)\n",
        "# #       .runas_op['video_id', 'id'](func=lambda x: int(x[-4:]))\n",
        "# #       .video_decode.ffmpeg['video_path', 'frames'](sample_type='uniform_temporal_subsample', args={'num_samples': 12})\n",
        "# #       .runas_op['frames', 'frames'](func=lambda x: [y for y in x])\n",
        "# #       .video_text_embedding.clip4clip['frames', 'vec'](model_name='clip_vit_b32', modality='video')\n",
        "# #       .to_milvus['id', 'vec'](collection=collection, batch=30)\n",
        "# # )\n",
        "# # print('Total number of inserted data is {}.'.format(collection.num_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2XgYH03XcJ"
      },
      "outputs": [],
      "source": [
        "# # device = 'cuda:0'\n",
        "# dc = (\n",
        "#     towhee.read_csv(test_sample_csv_path).unstream()\n",
        "#       .video_text_embedding.clip4clip['sentence','text_vec'](model_name='clip_vit_b32', modality='text')\n",
        "#       .milvus_search['text_vec', 'top10_raw_res'](collection='text_video_retrieval', limit=10)\n",
        "#       .runas_op['video_id', 'ground_truth'](func=lambda x : [int(x[-4:])])\n",
        "#       .runas_op['top10_raw_res', 'top1'](func=lambda res: [x.id for i, x in enumerate(res) if i < 1])\n",
        "#       .runas_op['top10_raw_res', 'top5'](func=lambda res: [x.id for i, x in enumerate(res) if i < 5])\n",
        "#       .runas_op['top10_raw_res', 'top10'](func=lambda res: [x.id for i, x in enumerate(res) if i < 10])\n",
        "# )\n",
        "\n",
        "# dc.select['video_id', 'sentence', 'ground_truth', 'top10_raw_res', 'top1', 'top5', 'top10']().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViSp0_sk3UcC"
      },
      "outputs": [],
      "source": [
        "# benchmark = (\n",
        "#     dc.with_metrics(['mean_hit_ratio',])\n",
        "#         .evaluate['ground_truth', 'top1'](name='recall_at_1')\n",
        "#         .evaluate['ground_truth', 'top5'](name='recall_at_5')\n",
        "#         .evaluate['ground_truth', 'top10'](name='recall_at_10')\n",
        "#         .report()\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBIS7hwP3UcD"
      },
      "outputs": [],
      "source": [
        "# import gradio\n",
        "# import towhee.models.clip4clip\n",
        "\n",
        "# device = 'cuda:0'\n",
        "# collection='text_video_retrieval'\n",
        "# show_num = 3\n",
        "# with towhee.api() as api:\n",
        "#     milvus_search_function = (\n",
        "#          api.clip4clip(model_name='clip_vit_b32', modality='text', device=device)\n",
        "#             .milvus_search(collection=collection, limit=show_num)\n",
        "#             .runas_op(func=lambda res: [os.path.join(raw_video_path, 'video' + str(x.id) + '.mp4') for x in res])\n",
        "#             .as_function()\n",
        "#     )\n",
        "\n",
        "# interface = gradio.Interface(milvus_search_function, \n",
        "#                              inputs=[gradio.Textbox()],\n",
        "#                              outputs=[gradio.Video(format='mp4') for _ in range(show_num)]\n",
        "#                             )\n",
        "\n",
        "# interface.launch(inline=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8IEBOxZ3UcE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW9MNQjA3UcF"
      },
      "source": [
        "# Towhee text-image inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIugAWHf3UcG"
      },
      "outputs": [],
      "source": [
        "# for video in os.listdir(\"../AIChallenge_data/KeyFrames\"):\n",
        "#     fix_frame_df = pd.read_csv(os.path.join(\"../AIChallenge_data/Fix_KeyFrames/\",video +\".csv\"),names=[\"img\",\"frame\"])\n",
        "#     for i in range(len(fix_frame_df)):\n",
        "#         img_path_df = img_path_df.append({\"img_path\":os.path.join(\"KeyFrames\",video,fix_frame_df.iloc[i][\"img\"]),\n",
        "#         \"video_id\":video,\"frame\":fix_frame_df.iloc[i][\"frame\"]},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlyo0NQ93UcH"
      },
      "outputs": [],
      "source": [
        "# img_path_df.to_csv(\"key_frame_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtn07IS-3UcM"
      },
      "outputs": [],
      "source": [
        "# from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
        "\n",
        "# connections.connect(host='127.0.0.1', port='19530')\n",
        "\n",
        "# def create_milvus_collection(collection_name, dim):\n",
        "#     if utility.has_collection(collection_name):\n",
        "#         utility.drop_collection(collection_name)\n",
        "    \n",
        "#     fields = [\n",
        "#     FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
        "#     FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
        "#     ]\n",
        "#     schema = CollectionSchema(fields=fields, description='text image search')\n",
        "#     collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "#     # create IVF_FLAT index for collection.\n",
        "#     index_params = {\n",
        "#         'metric_type':'L2',\n",
        "#         'index_type':\"IVF_FLAT\",\n",
        "#         'params':{\"nlist\":512}\n",
        "#     }\n",
        "#     collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "#     return collection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"KeyFrames\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "NZRht4VXRDhf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/KeyFrames ."
      ],
      "metadata": {
        "id": "uuebue14RL0u"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sf-2G4Qn3UcN",
        "outputId": "7ec603a4-fbcb-49b1-f00d-1e7cea28dad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                        img_path   video_id  false_frame  frame\n",
              "0            0  KeyFrames\\C00_V0000\\000000.jpg  C00_V0000            0      0\n",
              "1            1  KeyFrames\\C00_V0000\\000096.jpg  C00_V0000           96     96\n",
              "2            2  KeyFrames\\C00_V0000\\000206.jpg  C00_V0000          206    206\n",
              "3            3  KeyFrames\\C00_V0000\\000378.jpg  C00_V0000          378    378\n",
              "4            4  KeyFrames\\C00_V0000\\000545.jpg  C00_V0000          545    545\n",
              "...        ...                             ...        ...          ...    ...\n",
              "226631  226631  KeyFrames\\C02_V0199\\051029.jpg  C02_V0199        51029  51029\n",
              "226632  226632  KeyFrames\\C02_V0199\\051040.jpg  C02_V0199        51040  51040\n",
              "226633  226633  KeyFrames\\C02_V0199\\051200.jpg  C02_V0199        51200  51200\n",
              "226634  226634  KeyFrames\\C02_V0199\\051360.jpg  C02_V0199        51360  51360\n",
              "226635  226635  KeyFrames\\C02_V0199\\051520.jpg  C02_V0199        51520  51520\n",
              "\n",
              "[226636 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "      <th>video_id</th>\n",
              "      <th>false_frame</th>\n",
              "      <th>frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000000.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000096.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000206.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000378.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>378</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>KeyFrames\\C00_V0000\\000545.jpg</td>\n",
              "      <td>C00_V0000</td>\n",
              "      <td>545</td>\n",
              "      <td>545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226631</th>\n",
              "      <td>226631</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051029.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51029</td>\n",
              "      <td>51029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226632</th>\n",
              "      <td>226632</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051040.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51040</td>\n",
              "      <td>51040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226633</th>\n",
              "      <td>226633</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051200.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51200</td>\n",
              "      <td>51200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226634</th>\n",
              "      <td>226634</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051360.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51360</td>\n",
              "      <td>51360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226635</th>\n",
              "      <td>226635</td>\n",
              "      <td>KeyFrames\\C02_V0199\\051520.jpg</td>\n",
              "      <td>C02_V0199</td>\n",
              "      <td>51520</td>\n",
              "      <td>51520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226636 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d96e5d6d-2c35-4128-83d1-3a2507f29ec8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_keyframes = pd.read_csv('key_frame_df.csv',index_col=0)\n",
        "df_keyframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tGcqXYbk3UcO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from towhee._types.image import Image\n",
        "\n",
        "id_img = df_keyframes.set_index('id')['img_path'].to_dict()\n",
        "def read_images(results):\n",
        "    imgs = []\n",
        "    for re in results:\n",
        "        # print(re)\n",
        "        path = id_img[re.id]\n",
        "        imgs.append(path)\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Faiss local and colab"
      ],
      "metadata": {
        "id": "lQfo70kTTre0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create image embeddings and build index\n",
        "(\n",
        "    towhee.read_csv('key_frame_df.csv')\n",
        "          .runas_op['id', 'id'](func=lambda x: int(x))\n",
        "          .set_parallel(4)\n",
        "          .image_decode['img_path', 'img']()\n",
        "          .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
        "          .tensor_normalize['vec','vec']()\n",
        "          .to_faiss[('id', 'vec')](findex='./index.bin')\n",
        ")"
      ],
      "metadata": {
        "id": "6nrtm_shTT0_",
        "outputId": "2f296e03-8152-4aac-b348-1368d3aeedc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000096.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000096.jpg failed, please check {'': '1', 'id': 1, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000096.jpg', 'video_id': 'C00_V0000', 'false_frame': '000096', 'frame': '96'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000206.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000206.jpg failed, please check {'': '2', 'id': 2, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000206.jpg', 'video_id': 'C00_V0000', 'false_frame': '000206', 'frame': '206'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000000.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000000.jpg failed, please check {'': '0', 'id': 0, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000000.jpg', 'video_id': 'C00_V0000', 'false_frame': '000000', 'frame': '0'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000378.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000378.jpg failed, please check {'': '3', 'id': 3, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000378.jpg', 'video_id': 'C00_V0000', 'false_frame': '000378', 'frame': '378'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000577.jpg failed\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000704.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000704.jpg failed, please check {'': '6', 'id': 6, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000704.jpg', 'video_id': 'C00_V0000', 'false_frame': '000704', 'frame': '704'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000794.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000794.jpg failed, please check {'': '7', 'id': 7, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000794.jpg', 'video_id': 'C00_V0000', 'false_frame': '000794', 'frame': '647'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "ERROR:root:Read image KeyFrames\\C00_V0000\\000545.jpg failed\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000545.jpg failed, please check {'': '4', 'id': 4, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000545.jpg', 'video_id': 'C00_V0000', 'false_frame': '000545', 'frame': '545'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n",
            "WARNING:towhee.engine:Read image KeyFrames\\C00_V0000\\000577.jpg failed, please check {'': '5', 'id': 5, 'img_path': 'KeyFrames\\\\C00_V0000\\\\000577.jpg', 'video_id': 'C00_V0000', 'false_frame': '000577', 'frame': '577'} with op <towhee.engine.factory._OperatorLazyWrapper object at 0x7f9ab64a9410>. Continue...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-aa64636b6987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mset_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mimage_decode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0;34m.\u001b[0m\u001b[0mimage_text_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clip_vit_b32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mtensor_normalize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mto_faiss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./index.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/hparam/hyperparameter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparam_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/functional/data_collection.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*arg, **kws)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m#         }):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/functional/data_collection.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, *arg)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__check_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__check_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeFlag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLBASEDFLAG\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeFlag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNKBASEDFLAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/factory.py\u001b[0m in \u001b[0;36m__check_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                   \u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                                   kwargs=self._kws)\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__vcall__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__has_vcall__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/factory.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(operator_src, tag, arg, kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_operator_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/operator_loader.py\u001b[0m in \u001b[0;36mload_operator\u001b[0;34m(self, function, arg, kws, tag)\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_operator_from_packages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                         self.load_operator_from_cache]:\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/operator_loader.py\u001b[0m in \u001b[0;36mload_operator_from_cache\u001b[0;34m(self, function, arg, kws, tag)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot find operator.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_operator_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOperator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/operator_loader.py\u001b[0m in \u001b[0;36mload_operator_from_path\u001b[0;34m(self, path, arg, kws)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_operator_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOperator\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/engine/operator_loader.py\u001b[0m in \u001b[0;36minstance_operator\u001b[0;34m(self, op, arg, kws)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mNOPOperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkws\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.towhee/operators/image-text-embedding/clip/main/clip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, modality)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         self.tfms = transforms.Compose([\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/towhee/models/clip/clip.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, weights_path, jit, device, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;31m# loading JIT archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/jit/_serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompilationUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mcpp_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_ir_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_extra_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         cpp_module = torch._C.import_ir_module_from_buffer(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p57OwU93UcQ"
      },
      "outputs": [],
      "source": [
        "# cd reverse_image_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l0AQEIr3UcR"
      },
      "outputs": [],
      "source": [
        "# query = \"The video is a continuous sketch of a foreign criminal. The first picture depicts a criminal and two policemen sitting in the back. The second picture has 14 people, including one person wearing a black shirt.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q31iZtz3UcS"
      },
      "outputs": [],
      "source": [
        "queries = {}\n",
        "with open(\"./query.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        query_name = line.split(\"//\")[0]\n",
        "        query = line.split(\"//\")[1]\n",
        "        queries[query_name] = query"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milvus local machine only"
      ],
      "metadata": {
        "id": "y3xS4t6MTjsO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsBDd7TP3UcP"
      },
      "outputs": [],
      "source": [
        "# # collection = create_milvus_collection('text_image_challenge_search', 512)\n",
        "# collection = create_milvus_collection('text_image_search', 512)\n",
        "# # collection = Collection('text_image_challenge_search')\n",
        "# dc = (\n",
        "#     towhee.read_csv('key_frame_df.csv')\n",
        "#       .runas_op['id', 'id'](func=lambda x: int(x))\n",
        "#       .set_parallel(4)\n",
        "#       .image_decode['img_path', 'img']()\n",
        "#       .image_text_embedding.clip['img', 'vec'](model_name='clip_vit_b32', modality='image')\n",
        "#       .tensor_normalize['vec','vec']()\n",
        "#       .to_milvus['id', 'vec'](collection='text_image_search', batch=100)\n",
        "      \n",
        "# )\n",
        "# print('Total number of inserted data is {}.'.format(collection.num_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wTlbBQr3UcS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for i in range(26,len(queries.keys())):\n",
        "#   key = list(queries.keys())[i]\n",
        "#   (\n",
        "#       towhee.dc['text']([queries[key]])\n",
        "#         .image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32', modality='text')\n",
        "#         .tensor_normalize['vec','vec']()\n",
        "#         .milvus_search['vec', 'result'](collection=collection, limit=100)\n",
        "#         .runas_op['result', 'result_img'](func=read_images)\n",
        "#         .select['result_img']()\n",
        "#         .to_csv(key+\".csv\")      \n",
        "#   )\n",
        "#   print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate query pack"
      ],
      "metadata": {
        "id": "JKCwm9mCR0wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://download039.fshare.vn/dl/hcL280KJz4ZEVrp8deuD4jastfEuPfRzeC8zbb7h6IC2mQKY7hd-pH7diN5uOkh2AbN4RiIRTjrXwh2C/query-pack-0.zip\n",
        "# !wget https://download039.fshare.vn/dl/kQpla+QWiPVNJn72Xh4ZWETidn2Wt4oq7Uty-VfCscQA2pL8-kexe9VU6jYwCgcrENcyy47XaofvjKCc/query-pack-1.zip\n",
        "# !wget https://download022.fshare.vn/dl/kWomGkkLX4UelE4fupVCUFlJmUkqiAVk56-42tZQ1e2+5VFjMMn78TTgvXzI7bElS1KnWpOw3EZ-JR+P/query-pack-2.zip"
      ],
      "metadata": {
        "id": "arimc3JxR4zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip query-pack-0.zip -d query-pack\n",
        "# !unzip query-pack-1.zip -d query-pack\n",
        "# !unzip query-pack-2.zip -d query-pack"
      ],
      "metadata": {
        "id": "CR3dzcrSSQtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf query-pack-0.zip\n",
        "# !rm -rf query-pack-1.zip\n",
        "# !rm -rf query-pack-2.zip"
      ],
      "metadata": {
        "id": "TFiZG871SitP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KOJT8803UcT",
        "outputId": "2ccae3ae-9466-4b8b-e598-2cd76a042aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Bản tin về một trận đấu của đội tuyển bóng đá Việt Nam. Các cầu thủ Việt Nam đang ăn mừng sau một bàn thắng. Đây không phải là đội tuyển quốc gia mà là đội tuyển U19. Bàn thắng nâng tỷ số lên 2-0 xuất phát từ một pha đánh đầu cận thành. Đối thủ của U19 Việt Nam là U19 Brunei.',\n",
              " 'Một hoạt động giải trí ưa thích của giới trẻ. Thả diều tại ngoại ô TPHCM. Trong bức hình có một chiếc diều khổng lồ hình con mực. Cùng ngày là phóng sự khởi công cầu Châu Đốc bắc qua song Hậu.',\n",
              " 'Một cuộc đua xe đồng đội, gồm người lớn và trẻ em. Những chiếc xe này không có động cơ, thay vào đó chúng được đẩy bởi các vị phụ huynh. Tại vạch xuất phát, có 3 người mặc đồ hóa trang thành những chú ngựa vằn. Bản tin này được phát vào ngày mà hôm trước đó là ngày Quốc khánh của nước Thụy Sĩ.',\n",
              " 'Một sở thú tại Trung Quốc với nhiều loài động vật khác nhau. Trong khung hình có 2 con hà mã. Một trong 2 đang uống nước. Ngoài hà mã, sở thú còn có voi và gấu trúc.',\n",
              " 'Một bức hình của Tổng thống Mỹ Joe Biden. Tổng thống Mỹ đang đeo kính đen. Đó là trang nhất của một bài báo. Tiêu đề tiếng Việt ghi: Mỹ có thể sẽ miễn thuế pin năng lượng mặt trời từ Việt Nam. Đó là một bài báo từ hãng tin Reuters.',\n",
              " 'Người nghệ nhân đang tô màu cho chiếc mặt nạ một cách tỉ mỉ. Xung quanh ông là rất nhiều những chiếc mặt nạ. Người nghệ nhân đi đôi dép tổ ong rất giản dị. Loại mặt nạ này được gọi là mặt nạ giấy bồi Trung thu.',\n",
              " 'Khung cảnh chứa 3-4 người trong những bộ trang phục sáng bóng. Trước đó là hình ảnh một đội quân xếp hàng, giống như một nghi lễ. Đây là những thành viên của Vệ binh Thụy Sĩ. Họ đang thực hiện lời tuyên thệ bảo vệ Giáo Hoàng.',\n",
              " 'Hình ảnh một người đàn ông cầm một bó hoa to. Anh đang ở một cửa hàng hoa. Cửa hàng này có tên là “Flower box”. Hình ảnh này nằm trong môt phóng sự về giá hoa hồng trong ngày Valentine.',\n",
              " 'Một người đàn ông đang chơi kèn saxophone. Đằng sau ông là một người khác đang chơi viola. Ngoài ra còn có một người chơi trống, và một cây dương cầm. Bốn nhạc cụ tạo thành một tứ tấu jazz (jazz quartet). Đây là một phần của sự kiện nhằm thắt chặt tình hữu nghị giữa nhóm các nước V4 với Việt Nam.',\n",
              " 'Một bức tượng của một nhân vật lịch sử nổi tiếng. Nhân vật này đang cưỡi ngựa. Tiêu đề tiếng Việt ghi: “Thẩm định tượng Đức Thánh Trần ở Hồ Mây, Vũng Tàu”. Bức tượng có màu vàng đồng.']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_dir = \"D:\\GitHub\\AIChallenge_data\\query-pack-0\\query-pack-0\"\n",
        "list_queries_file = os.listdir(query_dir)\n",
        "vi_queries = []\n",
        "for query in list_queries_file:\n",
        "    with open(os.path.join(query_dir,query),\"r\",encoding='utf8') as f:\n",
        "        read_line = f.readline()\n",
        "        vi_queries.append(read_line)\n",
        "\n",
        "vi_queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZBWcflX3UcU",
        "outputId": "6f19e55d-c3f8-4da1-a266-c89ea96da4ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The news of a match of Vietnamese football team. Vietnamese players are celebrating after a goal. This is not the national team but the U19 team. The goal that lifted the score to 2-0 came from a close-fitting header. Opponents of Vietnam U19 are Brunei U19.',\n",
              " 'A favorite recreational activity of young people. Flying kites in the suburbs of Ho Chi Minh City. In the picture there is a giant kite in the shape of a squid. On the same day was the launch of Chau Doc Bridge across the Hau parallel.',\n",
              " 'A team car race, consisting of adults and children. These cars do not have engines, instead they are pushed by the parents. At the starting line, there are 3 people dressed up as zebras. This newscast was broadcast on the day that the day before was the Swiss National Day.',\n",
              " 'A zoo in China with many different animals. In the frame there are 2 hippos. One of the 2 is drinking water. In addition to hippos, the zoo also has elephants and raccoons.',\n",
              " 'A picture of U.S. President Joe Biden. The U.S. President is wearing black glasses. It was the front page of an article. The Vietnamese title read: The U.S. may waive tariffs on solar cells from Vietnam. It was an article from Reuters news agency.',\n",
              " 'The artist is coloring the mask meticulously. Around him are a lot of masks. The artist wears very simple honeycomb slippers. This type of mask is called a Mid-Autumn paper mask.',\n",
              " 'The scene contains 3-4 people in shiny outfits. Before that is the image of an army lined up, which resembles a ritual. These are members of the Swiss Guard. They are taking the oath to protect the Pope.',\n",
              " 'Picture of a man holding a large bouquet of flowers. He is at a flower shop. This shop is called “Flower box\". This image is in a reportage about the price of roses on Valentine\\'s Day.',\n",
              " 'A man is playing the saxophone. Behind him is another man playing the viola. There is also a drummer, and a piano. The four instruments form a jazz quartet. This is part of the event to strengthen the friendship between the group of V4 countries with Vietnam.',\n",
              " 'A statue of a famous historical figure. This figure is riding a horse. The Vietnamese title reads: “Tham đinh tuong Đuc Thanh Tran o Ho May, Vung Tau\". The statue is bronze yellow.']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_queries = [translate_vi2en(x) for x in vi_queries]\n",
        "eng_queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlGg04oM3UcU"
      },
      "outputs": [],
      "source": [
        "(\n",
        "      towhee.dc['text'](eng_queries)\n",
        "        .image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32', modality='text')\n",
        "        .tensor_normalize['vec','vec']()\n",
        "        .milvus_search['vec', 'result'](collection=collection, limit=100)\n",
        "        .runas_op['result', 'result_img'](func=read_images)\n",
        "        .select['result_img']()\n",
        "        .to_csv(\"test\"+\".csv\")  \n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSUCI3qw3UcV"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"./test.csv\")\n",
        "df.result_img =df.result_img.apply(literal_eval)\n",
        "\n",
        "for i in range(len(list_queries_file)):\n",
        "    with open(\"{}_result.txt\".format(list_queries_file[i]),\"w\") as f:\n",
        "        list_img = df[\"result_img\"][i]\n",
        "        for img in list_img:\n",
        "            video_id = img.split(\"\\\\\")[-2]\n",
        "            false_frame = img.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "            real_frame = df_keyframes[df_keyframes.false_frame == int(false_frame)][video_id==df_keyframes.video_id].frame.values[0]\n",
        "            f.write(video_id + \".mp4, \" + str(real_frame) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCSoziOO3UcV"
      },
      "outputs": [],
      "source": [
        "# with towhee.api() as api:\n",
        "#     milvus_search_function = (\n",
        "#         api.image_text_embedding.clip(model_name='clip_vit_b32',modality='text')\n",
        "#             .tensor_normalize()\n",
        "#             .milvus_search(collection='text_image_search', limit=5)\n",
        "#             .runas_op(func=lambda res: [id_img[x.id] for x in res])\n",
        "#             .as_function()\n",
        "#     )\n",
        "\n",
        "# import gradio\n",
        "\n",
        "# interface = gradio.Interface(milvus_search_function, \n",
        "#                              gradio.inputs.Textbox(lines=1),\n",
        "#                              [gradio.outputs.Image(type=\"file\", label=None) for _ in range(5)]\n",
        "#                             )\n",
        "\n",
        "# interface.launch(inline=True, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjSAOMra3UcW"
      },
      "source": [
        "# Calculate score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn-thwdH3UcX",
        "outputId": "aa9da26a-90e5-4da2-83a5-469f5ed06f7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6.4"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "rank = [18,5,1,1,2,33,101,63,1,13]\n",
        "\n",
        "\n",
        "accept_rank = [1,5,20,50,100]\n",
        "score = []\n",
        "for i in range(len(rank)):\n",
        "    for j in range(len(accept_rank)):\n",
        "        score.append(1 if rank[i] <= accept_rank[j] else 0)\n",
        "\n",
        "total_score = np.sum(score) / 5\n",
        "total_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtPFHqv53UcY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 ('env4ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f684d485204dfdeef2abe219ca21370c20995e9c270e0d9ebbd2a2aeed1acfbd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}