{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\env4ml\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import towhee\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnamese Engslish Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map = {\n",
    "    \"òa\": \"oà\",\"Òa\": \"Oà\",\"ÒA\": \"OÀ\",\"óa\": \"oá\",\"Óa\": \"Oá\",\"ÓA\": \"OÁ\",\"ỏa\": \"oả\",\"Ỏa\": \"Oả\",\"ỎA\": \"OẢ\",\"õa\": \"oã\",\n",
    "    \"Õa\": \"Oã\",\"ÕA\": \"OÃ\",\"ọa\": \"oạ\",\"Ọa\": \"Oạ\",\"ỌA\": \"OẠ\",\"òe\": \"oè\",\"Òe\": \"Oè\",\"ÒE\": \"OÈ\",\"óe\": \"oé\",\"Óe\": \"Oé\",\n",
    "    \"ÓE\": \"OÉ\",\"ỏe\": \"oẻ\",\"Ỏe\": \"Oẻ\",\"ỎE\": \"OẺ\",\"õe\": \"oẽ\",\"Õe\": \"Oẽ\",\"ÕE\": \"OẼ\",\"ọe\": \"oẹ\",\"Ọe\": \"Oẹ\",\"ỌE\": \"OẸ\",\n",
    "    \"ùy\": \"uỳ\",\"Ùy\": \"Uỳ\",\"ÙY\": \"UỲ\",\"úy\": \"uý\",\"Úy\": \"Uý\",\"ÚY\": \"UÝ\",\"ủy\": \"uỷ\",\"Ủy\": \"Uỷ\",\"ỦY\": \"UỶ\",\"ũy\": \"uỹ\",\n",
    "    \"Ũy\": \"Uỹ\",\"ŨY\": \"UỸ\",\"ụy\": \"uỵ\",\"Ụy\": \"Uỵ\",\"ỤY\": \"UỴ\",\n",
    "    }\n",
    "\n",
    "def strip_accents(s):\n",
    "       return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"../AIChallenge_data/ViEnTranslate/\", src_lang=\"vi_VN\")\n",
    "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"../AIChallenge_data/ViEnTranslate/\")\n",
    "\n",
    "def translate_vi2en(vi_text: str) -> str:\n",
    "    for i, j in dict_map.items():\n",
    "        vi_text = vi_text.replace(i, j)\n",
    "    input_ids = tokenizer_vi2en(vi_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model_vi2en.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.8,\n",
    "        decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    en_text = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    en_text = \" \".join(en_text)\n",
    "    en_text = strip_accents(en_text)\n",
    "    en_text = en_text.replace(\"\\\\\",\"\")\n",
    "    return en_text\n",
    "\n",
    "# vi_text = \"Cô cho biết: trước giờ tôi không đến phòng tập công cộng, mà tập cùng giáo viên Yoga riêng hoặc tự tập ở nhà. Khi tập thể dục trong không gian riêng tư, tôi thoải mái dễ chịu hơn.\"\n",
    "# print(translate_vi2en(vi_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "connections.connect(host='127.0.0.1', port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\AIChallenge_data\n"
     ]
    }
   ],
   "source": [
    "%cd ../AIChallenge_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_keyframes = pd.read_csv('key_frame_df.csv',index_col=0)\n",
    "\n",
    "import cv2\n",
    "from towhee._types.image import Image\n",
    "\n",
    "id_img = df_keyframes.set_index('id')['img_path'].to_dict()\n",
    "def read_images(results):\n",
    "    imgs = []\n",
    "    for re in results:\n",
    "        # print(re)\n",
    "        path = id_img[re.id]\n",
    "        imgs.append(path)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-3.txt: Một sở thú tại Trung Quốc với nhiều loài động vật khác nhau. Trong khung hình có 2 con hà mã. Một trong 2 đang uống nước. Ngoài hà mã, sở thú còn có voi và gấu trúc.\n",
      "\n",
      "query-4.txt: Một bức hình của Tổng thống Mỹ Joe Biden. Tổng thống Mỹ đang đeo kính đen. Đó là trang nhất của một bài báo. Tiêu đề tiếng Việt ghi: Mỹ có thể sẽ miễn thuế pin năng lượng mặt trời từ Việt Nam. Đó là một bài báo từ hãng tin Reuters.\n",
      "\n",
      "query-5.txt: Người nghệ nhân đang tô màu cho chiếc mặt nạ một cách tỉ mỉ. Xung quanh ông là rất nhiều những chiếc mặt nạ. Người nghệ nhân đi đôi dép tổ ong rất giản dị. Loại mặt nạ này được gọi là mặt nạ giấy bồi Trung thu.\n",
      "\n",
      "---------------\n",
      "['A zoo in China with many different animals. In the frame there are 2 hippos. One of the 2 is drinking water. In addition to hippos, the zoo also has elephants and raccoons.', 'A picture of U.S. President Joe Biden. The U.S. President is wearing black glasses. It was the front page of an article. The Vietnamese title read: The U.S. may waive a tax on solar cells from Vietnam. It was an article from Reuters news agency.', 'The artisan is coloring the mask meticulously. Around him are a lot of masks. The artisan wears very simple honeycomb slippers. This type of mask is called a Mid-Autumn paper mask.']\n"
     ]
    }
   ],
   "source": [
    "query_dir = \"D:\\GitHub\\AIChallenge_data\\query-pack-0\\query-pack-0-3\"\n",
    "en_query_dir = os.path.join(os.path.dirname(query_dir),\"en_\"+ query_dir.split(\"\\\\\")[-1])\n",
    "try:\n",
    "    os.mkdir(en_query_dir)\n",
    "except:\n",
    "    pass\n",
    "list_queries_file = os.listdir(query_dir)\n",
    "en_queries = []\n",
    "for query in list_queries_file:\n",
    "    with open(os.path.join(query_dir,query),\"r\",encoding='utf8') as f:\n",
    "        with open(os.path.join(en_query_dir,\"en_\" + query),\"w\",encoding='utf8') as f_out:\n",
    "            read_line = f.readline()\n",
    "            print(\"{}: {}\\n\".format(query,read_line))\n",
    "            vi2en_text = translate_vi2en(read_line)\n",
    "            f_out.write(vi2en_text)\n",
    "            en_queries.append(vi2en_text)\n",
    "\n",
    "print(\"---------------\")\n",
    "print(en_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection(\"text_image_challenge_search\")\n",
    "(\n",
    "      towhee.dc['text'](en_queries)\n",
    "        .image_text_embedding.clip['text', 'vec'](model_name='clip_vit_b32', modality='text')\n",
    "        .tensor_normalize['vec','vec']()\n",
    "        .milvus_search['vec', 'result'](collection=collection, limit=100)\n",
    "        .runas_op['result', 'result_img'](func=read_images)\n",
    "        .select['text','result_img']()\n",
    "        .to_csv(\"test.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "df.result_img =df.result_img.apply(literal_eval)\n",
    "\n",
    "result_query_dir = os.path.join(os.path.dirname(query_dir),\"result\")\n",
    "try:\n",
    "    os.mkdir(result_query_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for i in range(len(list_queries_file)):\n",
    "    with open(os.path.join(result_query_dir,\"{}.csv\".format(list_queries_file[i].split(\".\")[0].replace(\"en_\",\"\"))),\"w\") as f:\n",
    "        list_img = df[\"result_img\"][i]\n",
    "        for img in list_img:\n",
    "            video_id = img.split(\"\\\\\")[-2]\n",
    "            false_frame = img.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "            real_frame = df_keyframes[df_keyframes.false_frame == int(false_frame)][video_id==df_keyframes.video_id].frame.values[0]\n",
    "            f.write(video_id + \".mp4, \" + str(real_frame) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('env4ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f684d485204dfdeef2abe219ca21370c20995e9c270e0d9ebbd2a2aeed1acfbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
